{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274b3cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openslide\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import json\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "from torch.utils import data\n",
    "# 개별 json 라벨 파일을 이용해 학습 데이터 리스트 생성\n",
    "import json\n",
    "import os\n",
    "from nets import nn\n",
    "from utils import util\n",
    "from utils.dataset import Dataset\n",
    "from torch.utils import data\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import torchvision\n",
    "from torch.nn.functional import cross_entropy\n",
    "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\",device)\n",
    "params={'names':{\n",
    "  0: 'pd-l1 negative tumor cell',\n",
    "  1: 'pd-l1 positive tumor cell',\n",
    "  2: 'non-tumor cell'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5e75e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir='../../model/yolov11/'\n",
    "model = nn.yolo_v11_x(len(params['names'])).to(device)\n",
    "checkpoint_path = os.path.join(save_dir, 'best_model.pt')\n",
    "if os.path.exists(checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device,weights_only=False)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "def visualize_detection_results(image, outputs, title=\"Cell Detection Results\"):\n",
    "    \"\"\"\n",
    "    검출 결과를 이미지에 시각화하는 함수\n",
    "    \n",
    "    Args:\n",
    "        image: PIL Image 또는 numpy array\n",
    "        outputs: (negative_tumor, positive_tumor, non_tumor) 튜플\n",
    "        title: 플롯 제목\n",
    "    \"\"\"\n",
    "    negative_tumor, positive_tumor, non_tumor = outputs\n",
    "    \n",
    "    # 이미지를 numpy array로 변환\n",
    "    if hasattr(image, 'convert'):  # PIL Image인 경우\n",
    "        img_array = np.array(image.convert('RGB'))\n",
    "    else:  # 이미 numpy array인 경우\n",
    "        img_array = image\n",
    "    \n",
    "    # 플롯 생성\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "    ax.imshow(img_array)\n",
    "    \n",
    "    # 각 클래스별로 다른 색상과 마커로 표시\n",
    "    colors = {\n",
    "        'negative': 'red',      # pd-l1 negative tumor cell\n",
    "        'positive': 'blue',     # pd-l1 positive tumor cell  \n",
    "        'non_tumor': 'green'    # non-tumor cell\n",
    "    }\n",
    "    \n",
    "    markers = {\n",
    "        'negative': 'o',\n",
    "        'positive': 's', \n",
    "        'non_tumor': '^'\n",
    "    }\n",
    "    \n",
    "    # 이미지 크기 (검출은 512x512에서 수행됨)\n",
    "    img_height, img_width = img_array.shape[:2]\n",
    "    \n",
    "    # Negative tumor cells 표시\n",
    "    if negative_tumor:\n",
    "        for cell in negative_tumor:\n",
    "            x, y = cell['x'], cell['y']\n",
    "            # 좌표를 이미지 크기에 맞게 스케일링 (필요시)\n",
    "            x_scaled = x * (img_width / 512) if img_width != 512 else x\n",
    "            y_scaled = y * (img_height / 512) if img_height != 512 else y\n",
    "            \n",
    "            ax.plot(x_scaled, y_scaled, markers['negative'], \n",
    "                   color=colors['negative'], markersize=8, alpha=0.7,\n",
    "                   label='PD-L1 Negative' if cell == negative_tumor[0] else \"\")\n",
    "    \n",
    "    # Positive tumor cells 표시  \n",
    "    if positive_tumor:\n",
    "        for cell in positive_tumor:\n",
    "            x, y = cell['x'], cell['y']\n",
    "            x_scaled = x * (img_width / 512) if img_width != 512 else x\n",
    "            y_scaled = y * (img_height / 512) if img_height != 512 else y\n",
    "            \n",
    "            ax.plot(x_scaled, y_scaled, markers['positive'], \n",
    "                   color=colors['positive'], markersize=8, alpha=0.7,\n",
    "                   label='PD-L1 Positive' if cell == positive_tumor[0] else \"\")\n",
    "    \n",
    "    # # Non-tumor cells 표시\n",
    "    # if non_tumor:\n",
    "    #     for cell in non_tumor:\n",
    "    #         x, y = cell['x'], cell['y']\n",
    "    #         x_scaled = x * (img_width / 512) if img_width != 512 else x\n",
    "    #         y_scaled = y * (img_height / 512) if img_height != 512 else y\n",
    "            \n",
    "    #         ax.plot(x_scaled, y_scaled, markers['non_tumor'], \n",
    "    #                color=colors['non_tumor'], markersize=8, alpha=0.7,\n",
    "    #                label='Non-tumor' if cell == non_tumor[0] else \"\")\n",
    "    \n",
    "    # 범례 추가\n",
    "    ax.legend(loc='upper right', bbox_to_anchor=(1, 1))\n",
    "    \n",
    "    # 축 설정\n",
    "    ax.set_title(title, fontsize=16)\n",
    "    ax.set_xlabel('X coordinate', fontsize=12)\n",
    "    ax.set_ylabel('Y coordinate', fontsize=12)\n",
    "    \n",
    "    # 검출 통계 정보 추가\n",
    "    stats_text = f'Detected cells:\\n'\n",
    "    stats_text += f'PD-L1 Negative: {len(negative_tumor)}\\n'\n",
    "    stats_text += f'PD-L1 Positive: {len(positive_tumor)}\\n' \n",
    "    # stats_text += f'Non-tumor: {len(non_tumor)}\\n'\n",
    "    stats_text += f'Total: {len(negative_tumor) + len(positive_tumor)}'\n",
    "    \n",
    "    ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, \n",
    "           verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return fig, ax\n",
    "\n",
    "def wh2xy(x):\n",
    "    y = x.clone() if isinstance(x, torch.Tensor) else np.copy(x)\n",
    "    y[:, 0] = x[:, 0] - x[:, 2] / 2  # top left x\n",
    "    y[:, 1] = x[:, 1] - x[:, 3] / 2  # top left y\n",
    "    y[:, 2] = x[:, 0] + x[:, 2] / 2  # bottom right x\n",
    "    y[:, 3] = x[:, 1] + x[:, 3] / 2  # bottom right y\n",
    "    return y\n",
    "\n",
    "def non_max_suppression(outputs, confidence_threshold=0.001, iou_threshold=0.65, class_thresholds=None, \n",
    "                        cross_class_nms=True, cross_class_iou_threshold=0.5):\n",
    "    \"\"\"\n",
    "    개선된 NMS - 클래스 내부 + 클래스 간 겹침 제거\n",
    "    \n",
    "    Args:\n",
    "        outputs: 모델 출력\n",
    "        confidence_threshold: 기본 confidence threshold\n",
    "        iou_threshold: 같은 클래스 내 NMS IoU threshold\n",
    "        class_thresholds: 클래스별 개별 threshold 딕셔너리\n",
    "        cross_class_nms: 다른 클래스 간 NMS 적용 여부\n",
    "        cross_class_iou_threshold: 다른 클래스 간 NMS IoU threshold\n",
    "    \"\"\"\n",
    "    max_wh = 4096      # 512x512 패치에 충분한 오프셋 (기존 7680에서 줄임)\n",
    "    max_det = 500      # 세포가 많을 수 있으므로 300 → 500으로 증가\n",
    "    max_nms = 10000 \n",
    "\n",
    "    bs = outputs.shape[0]\n",
    "    nc = outputs.shape[1] - 4\n",
    "    \n",
    "    # 빠른 필터링을 위해 가장 낮은 threshold 사용\n",
    "    min_conf = confidence_threshold\n",
    "    if class_thresholds:\n",
    "        min_conf = min(min(class_thresholds.values()), confidence_threshold)\n",
    "    \n",
    "    # 전체 confidence가 낮은 것들 먼저 제거\n",
    "    xc = outputs[:, 4:4 + nc].amax(1) > min_conf\n",
    "    \n",
    "    output = [torch.zeros((0, 6), device=outputs.device)] * bs\n",
    "    \n",
    "    for xi, x in enumerate(outputs):  # image index, image inference\n",
    "        x = x.transpose(0, -1)[xc[xi]]\n",
    "        \n",
    "        if not x.shape[0]:\n",
    "            continue\n",
    "\n",
    "        # 박스와 클래스 분리\n",
    "        box, cls = x.split((4, nc), 1)\n",
    "        box = wh2xy(box)\n",
    "        \n",
    "        # 각 검출의 최고 클래스와 confidence 찾기\n",
    "        conf, j = cls.max(1, keepdim=True)\n",
    "        x = torch.cat((box, conf, j.float()), 1)\n",
    "        \n",
    "        # 클래스별 threshold 적용\n",
    "        if class_thresholds:\n",
    "            keep = torch.zeros(x.shape[0], dtype=torch.bool, device=x.device)\n",
    "            for i, detection in enumerate(x):\n",
    "                class_id = int(detection[5].item())\n",
    "                threshold = class_thresholds.get(class_id, confidence_threshold)\n",
    "                if detection[4].item() >= threshold:\n",
    "                    keep[i] = True\n",
    "            x = x[keep]\n",
    "        else:\n",
    "            x = x[x[:, 4] > confidence_threshold]\n",
    "        \n",
    "        if not x.shape[0]:\n",
    "            continue\n",
    "            \n",
    "        # confidence로 정렬하고 상위 max_nms개만 유지\n",
    "        x = x[x[:, 4].argsort(descending=True)[:max_nms]]\n",
    "        \n",
    "        # 1단계: 클래스별 NMS (기존 방식)\n",
    "        c = x[:, 5:6] * max_wh  # 클래스별 offset\n",
    "        boxes_with_offset = x[:, :4] + c\n",
    "        scores = x[:, 4]\n",
    "        \n",
    "        # 클래스별 NMS 적용\n",
    "        keep_class = torchvision.ops.nms(boxes_with_offset, scores, iou_threshold)\n",
    "        x = x[keep_class]\n",
    "        \n",
    "        # 2단계: 다른 클래스 간 겹침 제거 (cross-class NMS)\n",
    "        if cross_class_nms and len(x) > 1:\n",
    "            # offset 없는 원본 박스로 다시 NMS\n",
    "            boxes_no_offset = x[:, :4]\n",
    "            scores = x[:, 4]\n",
    "            \n",
    "            # confidence가 높은 순으로 정렬\n",
    "            sorted_indices = scores.argsort(descending=True)\n",
    "            keep_indices = []\n",
    "            \n",
    "            for i in sorted_indices:\n",
    "                current_box = boxes_no_offset[i:i+1]\n",
    "                current_score = scores[i]\n",
    "                current_class = x[i, 5]\n",
    "                \n",
    "                # 이미 선택된 박스들과 IoU 계산\n",
    "                should_keep = True\n",
    "                if keep_indices:\n",
    "                    kept_boxes = boxes_no_offset[keep_indices]\n",
    "                    ious = torchvision.ops.box_iou(current_box, kept_boxes)\n",
    "                    \n",
    "                    # 다른 클래스와의 겹침 확인\n",
    "                    for j, kept_idx in enumerate(keep_indices):\n",
    "                        kept_class = x[kept_idx, 5]\n",
    "                        if ious[0, j] > cross_class_iou_threshold:\n",
    "                            # 겹치는 경우, confidence가 더 높은 것만 유지\n",
    "                            if current_score <= scores[kept_idx]:\n",
    "                                should_keep = False\n",
    "                                break\n",
    "                            else:\n",
    "                                # 현재 박스가 더 좋으면 기존 박스 제거\n",
    "                                keep_indices.remove(kept_idx)\n",
    "                \n",
    "                if should_keep:\n",
    "                    keep_indices.append(i.item())\n",
    "            \n",
    "            # 최종 결과\n",
    "            if keep_indices:\n",
    "                x = x[keep_indices]\n",
    "        \n",
    "        if x.shape[0] > max_det:\n",
    "            x = x[:max_det]\n",
    "        \n",
    "        output[xi] = x\n",
    "    \n",
    "    return output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3988c9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def pred_patch(torch_patch, model, start_x, start_y, magnification):\n",
    "    model.eval()\n",
    "    \n",
    "    # 클래스별 개별 confidence threshold 설정\n",
    "    class_thresholds = {\n",
    "        0: 0.15,  # pd-l1 negative tumor cell\n",
    "        1: 0.15,  # pd-l1 positive tumor cell \n",
    "        2: 1.0   # non-tumor cell\n",
    "    }\n",
    "    \n",
    "    negative_tumor = []\n",
    "    positive_tumor = []\n",
    "    non_tumor = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        with torch.amp.autocast('cuda'):\n",
    "            pred = model(torch_patch)\n",
    "        \n",
    "        # 개선된 NMS 적용 - 클래스 간 겹침도 제거\n",
    "        results = non_max_suppression(pred, \n",
    "                                    confidence_threshold=0.1, \n",
    "                                    iou_threshold=0.05,  # 같은 클래스 내 NMS threshold\n",
    "                                    class_thresholds=class_thresholds,\n",
    "                                    cross_class_nms=True,  # 다른 클래스 간 NMS 활성화\n",
    "                                    cross_class_iou_threshold=0.1)  # 다른 클래스 간 IoU threshold\n",
    "        \n",
    "        if len(results[0]) > 0:\n",
    "            # 벡터화된 처리로 속도 향상\n",
    "            detections = results[0]\n",
    "            xyxy = detections[:, :4]\n",
    "            confs = detections[:, 4]\n",
    "            cls_ids = detections[:, 5]\n",
    "            \n",
    "            # 중심점 계산 (벡터화)\n",
    "            centers_x = (xyxy[:, 0] + xyxy[:, 2]) / 2\n",
    "            centers_y = (xyxy[:, 1] + xyxy[:, 3]) / 2\n",
    "            \n",
    "            # 실제 좌표 계산\n",
    "            actual_x = start_x + centers_x * magnification\n",
    "            actual_y = start_y + centers_y * magnification\n",
    "            \n",
    "            # 클래스별로 분리 (벡터화)\n",
    "            for i in range(len(detections)):\n",
    "                cls_id = int(cls_ids[i].item())\n",
    "                cell_data = {\n",
    "                    'x': actual_x[i].item(), \n",
    "                    'y': actual_y[i].item(), \n",
    "                    'cls_id': cls_id,\n",
    "                    'confidence': confs[i].item()\n",
    "                }\n",
    "                \n",
    "                if cls_id == 0:\n",
    "                    negative_tumor.append(cell_data)\n",
    "                elif cls_id == 1:\n",
    "                    positive_tumor.append(cell_data)\n",
    "                # else:\n",
    "                #     non_tumor.append(cell_data)\n",
    "    \n",
    "    return negative_tumor, positive_tumor, non_tumor\n",
    "image_list=glob('../../data/Patch-based-dataset/train_data_patch/class_2+/*.png')\n",
    "img=Image.open(image_list[50]).resize((256,256))\n",
    "torch_img=torch.from_numpy(np.array(img)[:,:,:3]).permute(2,0,1).unsqueeze(0).float()/255.\n",
    "torch_img=torch_img.to(device)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs=pred_patch(torch_img, model, 0, 0, 512/256)\n",
    "\n",
    "visualize_detection_results(img, outputs, \"Cell Detection Results - Sample Image\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
